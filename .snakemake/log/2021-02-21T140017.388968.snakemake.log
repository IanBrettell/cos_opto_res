Building DAG of jobs...
Using shell: /usr/local/bin/bash
Provided cluster nodes: 5000
Job counts:
	count	jobs
	1	all
	2	tif2h5
	3

[Sun Feb 21 14:00:18 2021]
rule tif2h5:
    input: ../videos/20210203/raw/20210203_cab_50_green_80_op_0.6_sp-2_MMStack_Default.ome-004.tif
    output: ../videos/20210203/h5s/20210203_cab_50_green_80_op_0.6_sp-2_MMStack_Default.ome-004.h5
    jobid: 2
    wildcards: sample=20210203_cab_50_green_80_op_0.6_sp-2_MMStack_Default.ome-004

Submitted job 2 with external jobid 'Job <7707647> is submitted to default queue <research-rh74>.'.

[Sun Feb 21 14:00:18 2021]
rule tif2h5:
    input: ../videos/20210203/raw/20210203_cab_50_green_90_op_0.6_sp_MMStack_Default.ome-006.tif
    output: ../videos/20210203/h5s/20210203_cab_50_green_90_op_0.6_sp_MMStack_Default.ome-006.h5
    jobid: 1
    wildcards: sample=20210203_cab_50_green_90_op_0.6_sp_MMStack_Default.ome-006

Submitted job 1 with external jobid 'Job <7707648> is submitted to default queue <research-rh74>.'.
Terminating processes on user request, this might take some time.
Will exit after finishing currently running jobs.
Complete log: /hps/research1/birney/users/ian/opto_res/cos_opto_res/.snakemake/log/2021-02-21T140017.388968.snakemake.log
