---
title: "COSMIKK behaviour notebook"
output: html_notebook
editor_options:
  chunk_output_type: inline
---

# Setup

## `conda` env

```{bash}
# Linux tools
mamba create -n opto_env av h5py fiji
conda activate opto_env
mamba install -c conda-forge av h5py
#mamba install -c bioconda fiji

# R
conda activate baseR
conda env export > code/snakemake/20210203/envs/baseR.yaml
```

## Singularity

```{bash}
module load singularity

# R with all 
singularity build \
  --remote ../sing_conts/baseR.sif \
  envs/20210306_baseR.def
  
# Ilastik
singularity build \
  --remote ../sing_conts/Ilastik.sif \
  envs/20210306_Ilastik.def
```

## `renv`

```{r, eval = F}
conda activate baseR
# initiate
renv::init()
# s
```

```{r, warning = F, message = F}
# conda activate baseR
#renv::activate()
library(here)
source(here::here("code", "scripts", "source.R"))
```


# Test data

Raw videos uploaded here: `/nfs/ftp/private/indigene_ftp/upload/OMR_Risa/`

Test video here on local: `~/Documents/Data/20210104_cos_videos/recorded_with_iphone.avi`

Tried segmenting using `idtrackerai`, but it couldn't distinguish the fish against the background.
As there are no crossovers, try `ilastik` intead.

## Convert AVI to H5 for Ilastik

```{r, engine='bash'}
python3 code/scripts/20210106_avi2h5_fynn.py \
  ~/Documents/Data/20210104_cos_videos/recorded_with_iphone.avi \
  ~/Documents/Data/20210104_cos_videos/recorded_with_iphone.h5
```

Stalls `Ilastik` and `Fiji`. Try converting from original with `opencv` with `scripts/20210106_avi2avi_opencv.py`.

Didn't work, even to mp4. Created no output. Try converting to a sequence first with `ffmpeg`.

```{r, engine='bash'}
mkdir /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone_seq

ffmpeg \
  -i "/Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone.avi" \
  -f image2 "/Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone_seq/%05d.png"
```

```{r, engine='bash'}
ffmpeg -i \
  /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone.avi \
  -vcodec copy \
  -acodec copy \
  /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone.mp4
```

```{r, engine='bash'}
ffmpeg \
  -i /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone.avi \
  -y /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone.mp4
```
Creates 19MB video. Try converting back to AVI.

```{r, engine='bash'}
ffmpeg \
  -i /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone.mp4 \
  -y /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone_backconv.avi
```

Creates a low-res video. Try with a different codec.

```{r, engine='bash'}
ffmpeg \
  -i /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone.mp4 \
  -vcodec copy \
  -acodec copy \
  -y /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone_backconv.avi
```

Doesn't play properly. Try to convert with python script anyway.

```{r, engine='bash'}
python3 code/scripts/20210106_avi2h5_fynn.py \
  ~/Documents/Data/20210104_cos_videos/recorded_with_iphone_backconv.avi \
  ~/Documents/Data/20210104_cos_videos/recorded_with_iphone_backconv.h5
```

Send to cluster to see if it works faster there.

```{r, engine='bash'}
ffmpeg \
  -i /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone.avi \
  -vcodec h264 \
  -y /Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone_h264.avi
```

Extracted frames 900-1100 using `Fiji`, now convert to `h5` for `Ilastik`

```{r, engine='bash'}
python3 code/scripts/20210106_avi2h5_fynn.py \
  ~/Documents/Data/20210104_cos_videos/recorded_with_iphone_900-1100.avi \
  ~/Documents/Data/20210104_cos_videos/recorded_with_iphone_900-1100.h5
```

# Try with DeepLabCut

Trimmed video with `Fiji` (virtualstack is better because doesn't need to load it into memory.)
Frames 250-1345, saved here: `/Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone_trimmed.avi`

Opened video with `Fiji` Import -> AVI, selected frames 250 to 1345, then Export -> AVI using jpeg compressed and saved here:
`/Users/brettell/Documents/Data/20210104_cos_videos/recorded_with_iphone_trimmed_jpeg.avi`

Use that for DeepLabCut and Ilastik.

Now convert that to `h5` for `Ilastik`:

```{r, engine='bash'}
python3 code/scripts/20210106_avi2h5_fynn.py \
  ~/Documents/Data/20210104_cos_videos/recorded_with_iphone_trimmed_jpeg.avi \
  ~/Documents/Data/20210104_cos_videos/recorded_with_iphone_trimmed_jpeg.h5
```

Also convert original .mov to .avi

```{r, engine='bash'}
ffmpeg \
  -i ~/Documents/Data/20210104_cos_videos/raw_vid.mov \
  -vcodec h264 \
  -acodec copy \
  ~/Documents/Data/20210104_cos_videos/raw_vid.avi
```
Import `raw_vid.mov` directly to `Fiji`, then save as uncompressed .avi:
`~/Documents/Data/20210104_cos_videos/raw_vid_fiji.avi` (note large file of 6.3GB)
Open that .avi, extract frames 900-1000, rotate, and save as:
`~/Documents/Data/20210104_cos_videos/raw_vid_fiji_short.avi`

*20210114*

New video:

`~/Documents/Data/20210104_cos_videos/20210108_OMR_Metal_halide_injured_Cab_MMStack_Default.ome.tif`

Converted to jpeg-compressed avi with `Fiji`:
`~/Documents/Data/20210104_cos_videos/20210108_OMR_Metal_halide_injured_Cab_MMStack_Default.ome_jpegcomp.avi`

*20210122*

Convert to `h5` for Ilastik using script

```{r, engine='bash'}
python code/scripts/20210106_avi2h5_fynn.py \
  ~/Documents/Data/20210104_cos_videos/20210108_OMR_Metal_halide_injured_Cab_MMStack_Default.ome_jpegcomp.avi \
  ~/Documents/Data/20210104_cos_videos/20210108_OMR_Metal_halide_injured_Cab_MMStack_Default.ome_jpegcomp.h5
```

Loads super slowly on the local. Try on the cluster.

Convert video:

```{r, engine='bash'}
python code/scripts/20210106_avi2h5_fynn.py \
  ../videos/20210108_OMR_Metal_halide_injured_Cab_MMStack_Default.ome_jpegcomp.avi \
  ../videos/20210108_OMR_Metal_halide_injured_Cab_MMStack_Default.ome_jpegcomp.h5
```


Tracking params:

* Method: simple
* Input: 1
* Threshold: 0.60
* Size filter min: 200 max: 2000

Frames to refine (/250)

115, 156, 221, 34, 69

________________________

*20210221* 

# Test on 3 videos

Raw videos here: `/nfs/ftp/private/indigene_ftp/upload/OMR_Risa/20210203`
Converted videos here: `/nfs/software/birney/users/ian/opto_res/videos/20210203_test`

## Pixel classification

```{bash, eval = F}
snmk_proj=20210203

conda activate snakemake
snakemake \
  --jobs 5000 \
  --latency-wait 1000 \
  --cluster-config code/snakemake/$snmk_proj/config/cluster.json \
  --cluster 'bsub -g /snakemake_bgenie -J {cluster.name} -n {cluster.n} -M {cluster.memory} -o {cluster.output} -e {cluster.error}' \
  --keep-going \
  --rerun-incomplete \
  --use-conda \
  --use-singularity \
  -s code/snakemake/$snmk_proj/Snakefile \
  -p
```

*20210302*

## Copy all videos in upload directory to working directory

`/nfs/ftp/private/indigene_ftp/upload/OMR_Risa`

```{bash}
in_dir=/nfs/ftp/private/indigene_ftp/upload/OMR_Risa
out_dir=../videos/20210302_batch

mkdir -p $out_dir

for file in $(find $in_dir/2021022* -type f -name "*.tif") ; do
  bn=$(basename $file) ;
  out_file=$out_dir/$bn ;
  if [ ! -f "$out_file" ] ; then
    cp $file $out_dir/$bn 
  fi ;
done
```

## Get frame counts and paste to file

```{bash, eval = F}
conda activate opto_env

in_dir=../videos/20210302_batch
out_file=

# Get file names
for file in $(find $in_dir/*.tif ) ; do
  basename $file ;
done > tmp.txt

# Get 
for file in $(find $in_dir/*.tif ) ; do
  mediainfo $file | grep "Title" | cut -f2 -d'/' | sed 's/\ frames=//g' ;
done > tmp2.txt

paste -d',' tmp.txt tmp2.txt > code/snakemake/20210203/config/samples.csv

rm tmp*
```

## Get random frames for each video 

```{r}
library(tidyverse)
library(ijtiff)

in_dir = "videos/20210203/tifs"
out_file = "cos_opto_res/code/snakemake/20210203/config/samples.csv"
n_frames = 10

# Get full path of files
files = list.files(in_dir, full.names = T)

# Get frames
frames = unlist(lapply(files, ijtiff::count_frames))

# Get max X and Y
max_x = integer()
max_y = integer()
lapply(seq_along(files), function(i) {
  target_tif = ijtiff::read_tif(files[i], frames = 1)
  max_x[i] <<- dim(target_tif)[2]
  max_y[i] <<- dim(target_tif)[1]
})

df = data.frame("SAMPLE" = files,
                "TOTAL_FRAMES" = frames,
                "MAX_X" = max_x,
                "MAX_Y" = max_y) %>% 
  dplyr::mutate(SAMPLE = stringr::str_remove(basename(SAMPLE), ".ome.tif")) %>% 
  dplyr::mutate(LAST_SAMPLE  = TOTAL_FRAMES - (n_frames - 1))

# get column index
target_index = which(colnames(df) == "LAST_SAMPLE")

# get random start frames
set.seed(63)
df$SAMPLE_START = sapply(1:nrow(df), function(x){
  sample(1:df[[x, target_index]], size = 1)
})

# add end frame and write to file
df %>% 
  dplyr::mutate(SAMPLE_END = SAMPLE_START + (n_frames - 1)) %>% 
  dplyr::select(SAMPLE, TOTAL_FRAMES, MAX_X, MAX_Y, SAMPLE_START, SAMPLE_END) %>% 
  readr::write_csv(out_file)
```

```{bash}
sample=20210226_1_4dpi1dpi_cabcr5inj2_W50_sp0.93_op80_GW_MMStack_Default

/ilastik-release/run_ilastik.sh \
  --headless \
  --readonly \
  --project=../ilastik/projects/20210107_test_anitrack.ilp \
  --raw_data=../ilastik/training/20210306/h5s/$sample.h5 \
  --input_axes="ztyxc" \
  --prediction_maps=../ilastik/training/20210306/h5s/$sample\_Probabilities.h5 \
  --export_source="Plugin" \
  --export_plugin="CSV-Table" \
  --output_filename_format=../ilastik/training/20210306/results/pass_1/raw/$sample\_CSV-Table.csv
  
#Exception: Error parsing command-line arguments for tracking data export applet.
#export_plugin should only be specified if export_source is set to Plugin.
```


# Process videos
```{r}
in_file = "~/Desktop/20210226_2_4dpi1dpi_cabcr5inj2_W50_sp0.93_op80_GW_MMStack_Default_CSV-Table.csv.csv"

cols = c("i", "_", "i", rep("_", 35), "d", "d", rep("_", 8))
cols = paste(cols, collapse = "")

# Import CSV and extract key columns

test = readr::read_csv(in_file,
                col_types = cols)


test %>% 
  ggplot() +
    geom_path(aes(Object_Center_0, Object_Center_1, colour = frame)) +
    facet_wrap(~trackId)

lane_1_end = 135
lane_2_end = 276
lane_3_end = 429
lane_4_end = 567
lane_5_end = 712
lane_6_end = 860
lane_7_end = max(test$Object_Center_1 + 1)


breaks = c(0, lane_1_end, lane_2_end, lane_3_end, lane_4_end, lane_5_end, lane_6_end, lane_7_end)
```

```{r}
df = test %>% 
  dplyr::filter(trackId != -1) %>% 
  dplyr::mutate(LANE = cut(Object_Center_1, breaks = breaks, labels = F)) %>% 
  dplyr::arrange(LANE, frame) %>% 
  split(., f = .$LANE) %>% 
  bind_rows()
```

```{r}
df %>% 
  ggplot() +
    geom_path(aes(Object_Center_0, Object_Center_1, group = LANE, colour = frame)) +
    scale_colour_viridis_c() +
    coord_fixed() #+
#transition_time(frame) +
#    ease_aes('linear')
```

## Tile plot to show which frames have registered
```{r}
df %>% 
  ggplot() +
    geom_tile(aes(frame, LANE, fill = frame))
```

## Find frames with least coverage

```{r}
samples_file = readr::read_csv(here::here("code", "snakemake", "20210203", "config", "samples.csv"))
```



## Experiment with `magick` to add horizontal lines splitting lanes

```{r}
library(ijtiff)
library(magick)

samples_file = readr::read_csv(here::here("code", "snakemake", "20210203", "config", "samples.csv"))

in_file = "videos/20210203/tifs/20210227_6_5dpi2dpi_cabcr5inj2_W50_sp1_op80_LGG_MMStack_Default.ome.tif"
out_file = "tmp.png"

# read first frame of tiff
frame_1 = ijtiff::read_tif(in_file, frames = 1)

# display
display(frame_1)

# write to file (magick can't read directly...)
ijtiff::write_tif(frame_1, "tmp.tif")

# convert to magick image
frame_1_m = magick::image_read("tmp.tif")

# display
magick::image_display(frame_1_m)

# very big. show smaller
magick::image_scale(frame_1_m, 1000) %>% 
  magick::image_modulate(brightness = 700) %>% 
#  magick::image_contrast(sharpen = 1) %>% 
  magick::image_display() 
  

# add horizontal lines
line_coords = c(135, 276, 429, 567, 712, 860)

img = magick::image_draw(frame_1_m)
abline(h = line_coords, col = "white")

lined_img = image_scale(img, 1000) %>% 
  magick::image_modulate(brightness = 700)
dev.off()

image_write(lined_img, path = out_file, format = "png")
```

```{r}
sample_name = unlist(sample_name)

lanes_n = samples_df %>% 
  dplyr::filter(SAMPLE == sample_name) %>% 
  dplyr::pull(TOTAL_LANES)

lane_coords = samples_df %>%
  dplyr::filter(SAMPLE == sample_name) %>% 
  dplyr::select(starts_with("END_LANE")) %>%
  subset(select = 1:lanes_n -1) %>% 
  unlist(use.names = F)
```


## Add line coords to samples file
```{r}
line_coords = c(135, 276, 429, 567, 712, 860)
samples_file_path = here::here("code", "snakemake", "20210203", "config", "samples.csv")

samples_file = readr::read_csv(samples_file_path)

samples_file %>%
  dplyr::mutate(TOTAL_LANES = 7,
                END_LANE_1 = line_coords[1],
                END_LANE_2 = line_coords[2],
                END_LANE_3 = line_coords[3],
                END_LANE_4 = line_coords[4],
                END_LANE_5 = line_coords[5],
                END_LANE_6 = line_coords[6]) %>% 
  readr::write_csv(samples_file_path)
  
```

## Choose samples to use in next pass

### Plot tiles for all files

#### Read and process data

```{r, message = F}
samples_file = here::here("code", "snakemake", "20210203", "config", "samples.csv")
in_dir = here::here("data", "tracking", "20210203", "pass_1")

# Get samples metadata
samples_df = readr::read_csv(samples_file)

# Get list of files
files = list.files(in_dir, full.names = T)
names(files) = basename(files) %>% 
  stringr::str_remove(".csv")

# Read all into list
df_list = lapply(files, function(file){
  # get sample name
  sample_name = basename(file) %>% 
    stringr::str_remove(".csv")
  # get target_row from samples_df
  target_row = samples_df %>% 
    dplyr::filter(SAMPLE == sample_name)
  # set up output list
  out = list()
  # get sample name
  out[["META"]] = list()
  out[["META"]][["SAMPLE"]] = sample_name
  # add some metadata
  out[["META"]][["TOTAL_FRAMES"]] = target_row %>% 
    dplyr::pull(TOTAL_FRAMES)
  out[["META"]][["MAX_Y"]] = target_row %>% 
    dplyr::pull(MAX_Y)
  out[["META"]][["N_LANES"]] = target_row %>% 
    dplyr::pull(TOTAL_LANES)
  
  # add lane breaks
  lanes_n = out$META$N_LANES
  
  out[["META"]][["LANE_BREAKS"]] = samples_df %>%
    dplyr::filter(SAMPLE == out$META$SAMPLE) %>%
    dplyr::select(starts_with("END_LANE")) %>%
    subset(select = 1:lanes_n -1) %>%
    unlist(use.names = F) %>% 
    c(0, ., out$META$MAX_Y)
  
  # add tracking data
  out[["RAW"]] = readr::read_csv(file)
  
  # process by dividing by lane
  out[["CLEAN"]] = out$RAW %>% 
    dplyr::filter(TRACKID != -1) %>% 
    dplyr::mutate(LANE = cut(COORD_Y,
                             breaks = out$META$LANE_BREAKS,
                             labels = F)) %>% 
    dplyr::arrange(LANE, FRAME) 
  
  return(out)
})
```

#### Plot

```{r}
out_path = here::here("plots", "20210203", "pass_1", "tiles", "tile.png")

lapply(df_list, function(SAMPLE){
  SAMPLE$CLEAN
}) %>% 
  dplyr::bind_rows(.id = "SAMPLE") %>% 
  ggplot() +
    geom_tile(aes(FRAME, LANE, fill = LANE)) +
    facet_wrap(~SAMPLE, ncol = 1) +
    scale_fill_viridis()

ggsave(out_path, 
       device = "png",
       width = 20,
       height = 40,
       units = "cm",
       dpi = 400)
  
```

### Find frames that were the least tracked
```{r}
n_frames = 10

# Find frames only covered by one lane
poor_tracking = lapply(df_list, function(SAMPLE){
  SAMPLE$CLEAN
}) %>% 
  dplyr::bind_rows(.id = "SAMPLE") %>% 
  dplyr::group_by(SAMPLE, FRAME) %>% 
  dplyr::count() %>% 
  dplyr::filter(n <= 1)

set.seed(72)
poor_frames = lapply(unique(poor_tracking$SAMPLE), function(target_sample){
  # get final frame
  final_frame = df_list[[SAMPLE]]$META$TOTAL_FRAMES
  # get last frame to sample
  final_frame_sample = final_frame - n_frames
  # extract random frame
  target_frame = poor_tracking %>% 
    dplyr::filter(SAMPLE == target_sample & FRAME <= final_frame_sample) %>% 
    dplyr::ungroup() %>% 
    dplyr::slice_sample(n = 1) %>% 
    dplyr::pull(FRAME)
  
  # create output df
  out = data.frame(SAMPLE = target_sample,
                   TOTAL_FRAMES = final_frame,
                   SAMPLE_START = target_frame,
                   SAMPLE_END = target_frame + (n_frames -1 ))
}) %>% 
  dplyr::bind_rows()
```

## Bind into single training DF
```{r}
batch = "20210203"
samples_file = here::here("code", "snakemake", batch, "config", "samples.csv")
in_dir = here::here("data", "tracking", batch, "pass_1")
out_file = here::here("code", "snakemake", batch, "config", "samples_pass_2_training.csv")

# Read samples DF
samples_df = readr::read_csv(samples_file)

# List completed files
samples_complete = list.files(in_dir) %>% 
  stringr::str_remove(".csv")

# Find incomplete samples
samples_incomplete = samples_df$SAMPLE[which(!samples_df$SAMPLE %in% samples_complete)]

# Bind back to original DF
training_samples = data.frame(SAMPLE = samples_incomplete) %>% 
  dplyr::left_join(dplyr::select(samples_df, SAMPLE, TOTAL_FRAMES, SAMPLE_START, SAMPLE_END),
                   by = "SAMPLE")

# get random start and end
final_nontracked = get_random_start(training_samples,
                                    n_frames = 10,
                                    seed = 82)

# Bind non-tracked to poorly-tracked DFs
final_samples = bind_rows(final_nontracked,
                          poor_frames)

# Write to file
readr::write_csv(final_samples, out_file)
```

## Pass 2 plots

### Proccess

```{r, message = F}
samples_file = here::here("code", "snakemake", "20210203", "config", "samples.csv")
in_dir = here::here("data", "tracking", "20210203", "pass_2")

df_list = process_tracking(samples_file = samples_file, in_dir = in_dir)
```

### Tiles

```{r}
out_path = here::here("plots", "20210203", "pass_2", "tiles")

generate_tile_plot(df_list = df_list, out_path = out_path, pass = 2)
```

### Paths

```{r}
pass = 2
out_path = here::here("plots", "20210203", paste("pass_", pass, sep = ""), "paths")

generate_path_plot(df_list = df_list, out_path = out_path, pass = pass)
```
### Collapse into single data file and write to table

```{r}
out_path = here::here("data", "tracking", "20210203", "pass_2_final")
dir.create(out_path, recursive = T)
out_file = file.path(out_path, "pass_2_final.csv")

lapply(df_list, function(SAMPLE){
  SAMPLE$CLEAN
}) %>%
  dplyr::bind_rows(.id = "SAMPLE") %>%
  dplyr::select(SAMPLE, LANE, FRAME, COORD_X, COORD_Y) %>% 
  readr::write_csv(out_file)
```

## Pass 3 

### Get frames for training
```{r, eval = F}
samples_file = here::here("code", "snakemake", "20210203", "config", "samples.csv")
prev_pass = here::here("data", "tracking", "20210203", "pass_2_final", "pass_2_final.csv")
out_file = here::here("code", "snakemake", "20210203", "config", "samples_pass_3_training.csv")

final_samples = get_training_samples(samples_file, prev_pass, seed = 80)

# Write to file
readr::write_csv(final_samples, out_file)
```

### Proccess

```{r, message = F}
samples_file = here::here("code", "snakemake", "20210203", "config", "samples.csv")
in_dir = here::here("data", "tracking", "20210203", "pass_3")

df_list = process_tracking(samples_file = samples_file, in_dir = in_dir)
```

### Tiles

```{r}
out_path = here::here("plots", "20210203", "pass_3", "tiles")

generate_tile_plot(df_list = df_list, out_path = out_path, pass = 3)
```

### Paths

```{r}
pass = 3
out_path = here::here("plots", "20210203", paste("pass_", pass, sep = ""), "paths")

generate_path_plot(df_list = df_list, out_path = out_path, pass = pass)
```
### Collapse into single data file and write to table

```{r}
out_path = here::here("data", "tracking", "20210203", "pass_3_final")
dir.create(out_path, recursive = T)
out_file = file.path(out_path, "pass_3_final.csv")

lapply(df_list, function(SAMPLE){
  SAMPLE$CLEAN
}) %>%
  dplyr::bind_rows(.id = "SAMPLE") %>%
  dplyr::select(SAMPLE, LANE, FRAME, COORD_X, COORD_Y) %>% 
  readr::write_csv(out_file)
```


# Try new videos with idtrackerai

*20210414*



